
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../NativeLibraryConfig/">
      
      
        <link rel="next" href="../ChatSession/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.16">
    
    
      
        <title>Use executors - LLamaSharp Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.bcfcd587.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llamasharp-executors" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLamaSharp Documentation" class="md-header__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLamaSharp Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Use executors
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLamaSharp Documentation" class="md-nav__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    LLamaSharp Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../QuickStart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Architecture
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../FAQ/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ContributingGuide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing Guide
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NativeLibraryConfig/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize the native library loading
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Use executors
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Use executors
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-to-text-apis-of-the-executors" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Text APIs of the executors
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactiveexecutor-instructexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      InteractiveExecutor &amp; InstructExecutor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statelessexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      StatelessExecutor.
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batchedexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedExecutor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Inference parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#save-and-load-executor-state" class="md-nav__link">
    <span class="md-ellipsis">
      Save and load executor state
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ChatSession/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use ChatSession
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../UnderstandLLamaContext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understand LLamaContext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GetEmbeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Get embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantize the model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Integrations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Integrations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/semantic-kernel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    semantic-kernel integration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/kernel-memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    kernel-memory integration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/BotSharp.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BotSharp integration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/Langchain.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Langchain integration
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorFork/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bacthed executor - multi-output to one input
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorGuidance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Batched executor - basic guidance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorRewind/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Batched executor - rewinding to an earlier state
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatChineseGB2312/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chinese LLM - with GB2312 encoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionStripRoleName/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatSession - stripping role names
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithHistory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatSession - with history
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRestart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatSession - restarting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRoleName/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatSession - Basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/CodingAssistant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Coding assistant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GetEmbeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Get embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GrammarJsonResponse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grammar - json response
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InstructModeExecute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Instruct executor - basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InteractiveModeExecute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interactive executor - basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kernel memory integration - basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemorySaveAndLoad/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kernel-memory - save & load
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LLavaInteractiveModeExecute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLaVA - basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveSession/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatSession - load & save
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveState/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Executor - save/load state
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/QuantizeModel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelChat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic-kernel - chat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelMemory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic-kernel - with kernel-memory
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelPrompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semantic-kernel - basic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/StatelessModeExecute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stateless executor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/TalkToYourself/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Talk to yourself
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    index
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.adaptercollection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.adaptercollection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.icontextparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.icontextparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.ihistorytransform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.ihistorytransform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.iinferenceparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.iinferenceparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.illamaexecutor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.illamaexecutor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.illamaparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.illamaparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.imodelparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.imodelparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.itextstreamtransform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.itextstreamtransform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.itexttransform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.itexttransform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.loraadapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.loraadapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.metadataoverride/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.metadataoverride
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.metadataoverrideconverter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.metadataoverrideconverter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.tensorsplitscollection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.tensorsplitscollection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.abstractions.tensorsplitscollectionconverter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.abstractions.tensorsplitscollectionconverter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.antipromptprocessor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.antipromptprocessor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.alreadypromptedconversationexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.alreadypromptedconversationexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.batchedexecutor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.batchedexecutor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.cannotforkwhilerequiresinferenceexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.cannotforkwhilerequiresinferenceexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.cannotmodifywhilerequiresinferenceexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.cannotmodifywhilerequiresinferenceexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.cannotsamplerequiresinferenceexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.cannotsamplerequiresinferenceexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.cannotsamplerequirespromptexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.cannotsamplerequirespromptexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.conversation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.conversation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.conversationextensions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.conversationextensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.batched.experimentalbatchedexecutorexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.batched.experimentalbatchedexecutorexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.chatsession-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.chatsession-1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.chatsession/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.chatsession
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.authorrole/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.authorrole
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.chathistory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.chathistory
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.fixedsizequeue-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.fixedsizequeue-1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.inferenceparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.inferenceparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.mirostattype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.mirostattype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.common.modelparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.common.modelparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarexpectedname/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarexpectedname
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarexpectednext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarexpectednext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarexpectedprevious/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarexpectedprevious
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarformatexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarformatexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunexpectedcharaltelement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunexpectedcharaltelement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunexpectedcharrngelement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunexpectedcharrngelement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunexpectedendelement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunexpectedendelement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunexpectedendofinput/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunexpectedendofinput
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunexpectedhexcharscount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunexpectedhexcharscount
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.grammarunknownescapecharacter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.grammarunknownescapecharacter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.llamadecodeerror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.llamadecodeerror
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.loadweightsfailedexception/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.loadweightsfailedexception
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.exceptions.runtimeerror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.exceptions.runtimeerror
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.extensions.icontextparamsextensions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.extensions.icontextparamsextensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.extensions.imodelparamsextensions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.extensions.imodelparamsextensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.grammars.grammar/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.grammars.grammar
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.grammars.grammarrule/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.grammars.grammarrule
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.ichatmodel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.ichatmodel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamacache/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamacache
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamaembedder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamaembedder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamamodel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamamodel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamamodelv1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamamodelv1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamaparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamaparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamaquantizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamaquantizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamastate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamastate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llamatransforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llamatransforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.llavaweights/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.llavaweights
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.decoderesult/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.decoderesult
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.ggmltype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.ggmltype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.gpusplitmode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.gpusplitmode
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamabatch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamabatch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamabeamsstate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamabeamsstate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamabeamview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamabeamview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamachatmessage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamachatmessage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamacontextparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamacontextparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamaftype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamaftype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamagrammarelement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamagrammarelement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamagrammarelementtype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamagrammarelementtype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamakvcacheview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamakvcacheview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamakvcacheviewcell/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamakvcacheviewcell
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamakvcacheviewsafehandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamakvcacheviewsafehandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamaloglevel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamaloglevel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamamodelkvoverridetype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamamodelkvoverridetype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamamodelmetadataoverride/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamamodelmetadataoverride
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamamodelparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamamodelparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamamodelquantizeparams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamamodelquantizeparams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamanativebatch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamanativebatch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamapoolingtype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamapoolingtype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamapos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamapos
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamaropetype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamaropetype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamaseqid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamaseqid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamatoken/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamatoken
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamatokendata/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamatokendata
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamatokendataarray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamatokendataarray
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamatokendataarraynative/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamatokendataarraynative
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamatokentype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamatokentype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llamavocabtype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llamavocabtype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.llavaimageembed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.llavaimageembed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.nativeapi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.nativeapi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.nativelibraryconfig/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.nativelibraryconfig
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.ropescalingtype/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.ropescalingtype
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellamacontexthandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellamacontexthandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellamagrammarhandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellamagrammarhandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellamahandlebase/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellamahandlebase
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellamamodelhandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellamamodelhandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellavaimageembedhandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellavaimageembedhandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.native.safellavamodelhandle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.native.safellavamodelhandle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.quantizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.quantizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.basesamplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.basesamplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.defaultsamplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.defaultsamplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.greedysamplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.greedysamplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.isamplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.isamplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.isamplingpipelineextensions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.isamplingpipelineextensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.mirostate2samplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.mirostate2samplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sampling.mirostatesamplingpipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sampling.mirostatesamplingpipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.sessionstate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.sessionstate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.streamingtokendecoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.streamingtokendecoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletionchoice/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletionchoice
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletionchunk/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletionchunk
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletionchunkchoice/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletionchunkchoice
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletionchunkdelta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletionchunkdelta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatcompletionmessage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatcompletionmessage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatmessagerecord/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatmessagerecord
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.chatrole/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.chatrole
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.completion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.completion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.completionchoice/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.completionchoice
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.completionchunk/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.completionchunk
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.completionlogprobs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.completionlogprobs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.completionusage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.completionusage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.embedding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.embeddingdata/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.embeddingdata
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/llama.types.embeddingusage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama.types.embeddingusage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../xmldocs/logger/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logger
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-to-text-apis-of-the-executors" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Text APIs of the executors
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactiveexecutor-instructexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      InteractiveExecutor &amp; InstructExecutor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statelessexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      StatelessExecutor.
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batchedexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      BatchedExecutor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Inference parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#save-and-load-executor-state" class="md-nav__link">
    <span class="md-ellipsis">
      Save and load executor state
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="llamasharp-executors">LLamaSharp executors</h1>
<p>LLamaSharp executor defines the behavior of the model when it is called. Currently, there are four kinds of executors, which are <code>InteractiveExecutor</code>, <code>InstructExecutor</code>, <code>StatelessExecutor</code> and <code>BatchedExecutor</code>.</p>
<p>In a word, <code>InteractiveExecutor</code> is suitable for getting answer of your questions from LLM continuously. <code>InstructExecutor</code> let LLM execute your instructions, such as "continue writing". <code>StatelessExecutor</code> is best for one-time job because the previous inference has no impact on the current inference. <code>BatchedExecutor</code> could accept multiple inputs and generate multiple outputs of different sessions at the same time, significantly improving the throughput of the program.</p>
<h2 id="text-to-text-apis-of-the-executors">Text-to-Text APIs of the executors</h2>
<p>All the executors implements the interface <code>ILLamaExecutor</code>, which provides two APIs to execute text-to-text tasks.</p>
<pre><code class="language-cs">public interface ILLamaExecutor
{
    /// &lt;summary&gt;
    /// The loaded context for this executor.
    /// &lt;/summary&gt;
    public LLamaContext Context { get; }

    // LLava Section
    //
    /// &lt;summary&gt;
    /// Identify if it's a multi-modal model and there is a image to process.
    /// &lt;/summary&gt;
    public bool IsMultiModal { get; }
    /// &lt;summary&gt;
    /// Muti-Modal Projections / Clip Model weights
    /// &lt;/summary&gt;
    public LLavaWeights? ClipModel { get;  }        

    /// &lt;summary&gt;
    /// List of images: Image filename and path (jpeg images).
    /// &lt;/summary&gt;
    public List&lt;string&gt; ImagePaths { get; set; }


    /// &lt;summary&gt;
    /// Asynchronously infers a response from the model.
    /// &lt;/summary&gt;
    /// &lt;param name=&quot;text&quot;&gt;Your prompt&lt;/param&gt;
    /// &lt;param name=&quot;inferenceParams&quot;&gt;Any additional parameters&lt;/param&gt;
    /// &lt;param name=&quot;token&quot;&gt;A cancellation token.&lt;/param&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    IAsyncEnumerable&lt;string&gt; InferAsync(string text, IInferenceParams? inferenceParams = null, CancellationToken token = default);
}
</code></pre>
<p>The output of both two APIs are <strong>yield enumerable</strong>. Therefore, when receiving the output, you can directly use <code>foreach</code> to take actions on each word you get by order, instead of waiting for the whole process completed.</p>
<h2 id="interactiveexecutor-instructexecutor">InteractiveExecutor &amp; InstructExecutor</h2>
<p>Both of them are taking "completing the prompt" as the goal to generate the response. For example, if you input <code>Long long ago, there was a fox who wanted to make friend with humen. One day</code>, then the LLM will continue to write the story.</p>
<p>Under interactive mode, you serve a role of user and the LLM serves the role of assistant. Then it will help you with your question or request. </p>
<p>Under instruct mode, you give LLM some instructions and it follows.</p>
<p>Though the behaviors of them sounds similar, it could introduce many differences depending on your prompt. For example, "chat-with-bob" has good performance under interactive mode and <code>alpaca</code> does well with instruct mode.</p>
<pre><code>// chat-with-bob

Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User's requests immediately and with precision.

User: Hello, Bob.
Bob: Hello. How may I help you today?
User: Please tell me the largest city in Europe.
Bob: Sure. The largest city in Europe is Moscow, the capital of Russia.
User:
</code></pre>
<pre><code>// alpaca

Below is an instruction that describes a task. Write a response that appropriately completes the request.
</code></pre>
<p>Therefore, please modify the prompt correspondingly when switching from one mode to the other.</p>
<h2 id="statelessexecutor">StatelessExecutor.</h2>
<p>Despite the differences between interactive mode and instruct mode, both of them are stateful mode. That is, your previous question/instruction will impact on the current response from LLM. On the contrary, the stateless executor does not have such a "memory". No matter how many times you talk to it, it will only concentrate on what you say in this time. It is very useful when you want a clean context, without being affected by previous inputs.</p>
<p>Since the stateless executor has no memory of conversations before, you need to input your question with the whole prompt into it to get the better answer.</p>
<p>For example, if you feed <code>Q: Who is Trump? A:</code> to the stateless executor, it may give the following answer with the antiprompt <code>Q:</code>.</p>
<pre><code>Donald J. Trump, born June 14, 1946, is an American businessman, television personality, politician and the 45th President of the United States (2017-2021). # Anexo:Torneo de Hamburgo 2022 (individual masculino)

## Presentación previa

* Defensor del título:  Daniil Medvédev
</code></pre>
<p>It seems that things went well at first. However, after answering the question itself, LLM began to talk about some other things until the answer reached the token count limit. The reason of this strange behavior is the anti-prompt cannot be match. With the input, LLM cannot decide whether to append a string "A: " at the end of the response.</p>
<p>As an improvement, let's take the following text as the input:</p>
<pre><code>Q: What is the capital of the USA? A: Washingtong. Q: What is the sum of 1 and 2? A: 3. Q: Who is Trump? A: 
</code></pre>
<p>Then, I got the following answer with the anti-prompt <code>Q:</code>.</p>
<pre><code>45th president of the United States.
</code></pre>
<p>At this time, by repeating the same mode of <code>Q: xxx? A: xxx.</code>, LLM outputs the anti-prompt we want to help to decide where to stop the generation.</p>
<h2 id="batchedexecutor">BatchedExecutor</h2>
<p>Different from other executors, <code>BatchedExecutor</code> could accept multiple inputs from different sessions and geneate outputs for them at the same time. Here is an example to use it.</p>
<pre><code class="language-cs">using LLama.Batched;
using LLama.Common;
using LLama.Native;
using LLama.Sampling;
using Spectre.Console;

namespace LLama.Examples.Examples;

/// &lt;summary&gt;
/// This demonstrates using a batch to generate two sequences and then using one
/// sequence as the negative guidance (&quot;classifier free guidance&quot;) for the other.
/// &lt;/summary&gt;
public class BatchedExecutorGuidance
{
    private const int n_len = 32;

    public static async Task Run()
    {
        string modelPath = UserSettings.GetModelPath();

        var parameters = new ModelParams(modelPath);
        using var model = LLamaWeights.LoadFromFile(parameters);

        var positivePrompt = AnsiConsole.Ask(&quot;Positive Prompt (or ENTER for default):&quot;, &quot;My favourite colour is&quot;).Trim();
        var negativePrompt = AnsiConsole.Ask(&quot;Negative Prompt (or ENTER for default):&quot;, &quot;I hate the colour red. My favourite colour is&quot;).Trim();
        var weight = AnsiConsole.Ask(&quot;Guidance Weight (or ENTER for default):&quot;, 2.0f);

        // Create an executor that can evaluate a batch of conversations together
        using var executor = new BatchedExecutor(model, parameters);

        // Print some info
        var name = executor.Model.Metadata.GetValueOrDefault(&quot;general.name&quot;, &quot;unknown model name&quot;);
        Console.WriteLine($&quot;Created executor with model: {name}&quot;);

        // Load the two prompts into two conversations
        using var guided = executor.Create();
        guided.Prompt(positivePrompt);
        using var guidance = executor.Create();
        guidance.Prompt(negativePrompt);

        // Run inference to evaluate prompts
        await AnsiConsole
             .Status()
             .Spinner(Spinner.Known.Line)
             .StartAsync(&quot;Evaluating Prompts...&quot;, _ =&gt; executor.Infer());

        // Fork the &quot;guided&quot; conversation. We'll run this one without guidance for comparison
        using var unguided = guided.Fork();

        // Run inference loop
        var unguidedSampler = new GuidedSampler(null, weight);
        var unguidedDecoder = new StreamingTokenDecoder(executor.Context);
        var guidedSampler = new GuidedSampler(guidance, weight);
        var guidedDecoder = new StreamingTokenDecoder(executor.Context);
        await AnsiConsole
           .Progress()
           .StartAsync(async progress =&gt;
            {
                var reporter = progress.AddTask(&quot;Running Inference&quot;, maxValue: n_len);

                for (var i = 0; i &lt; n_len; i++)
                {
                    if (i != 0)
                        await executor.Infer();

                    // Sample from the &quot;unguided&quot; conversation. This is just a conversation using the same prompt, without any
                    // guidance. This serves as a comparison to show the effect of guidance.
                    var u = unguidedSampler.Sample(executor.Context.NativeHandle, unguided.Sample(), Array.Empty&lt;LLamaToken&gt;());
                    unguidedDecoder.Add(u);
                    unguided.Prompt(u);

                    // Sample from the &quot;guided&quot; conversation. This sampler will internally use the &quot;guidance&quot; conversation
                    // to steer the conversation. See how this is done in GuidedSampler.ProcessLogits (bottom of this file).
                    var g = guidedSampler.Sample(executor.Context.NativeHandle, guided.Sample(), Array.Empty&lt;LLamaToken&gt;());
                    guidedDecoder.Add(g);

                    // Use this token to advance both guided _and_ guidance. Keeping them in sync (except for the initial prompt).
                    guided.Prompt(g);
                    guidance.Prompt(g);

                    // Early exit if we reach the natural end of the guided sentence
                    if (g == model.EndOfSentenceToken)
                        break;

                    // Update progress bar
                    reporter.Increment(1);
                }
            });

        AnsiConsole.MarkupLine($&quot;[green]Unguided:[/][white]{unguidedDecoder.Read().ReplaceLineEndings(&quot; &quot;)}[/]&quot;);
        AnsiConsole.MarkupLine($&quot;[green]Guided:[/][white]{guidedDecoder.Read().ReplaceLineEndings(&quot; &quot;)}[/]&quot;);
    }

    private class GuidedSampler(Conversation? guidance, float weight)
        : BaseSamplingPipeline
    {
        public override void Accept(SafeLLamaContextHandle ctx, LLamaToken token)
        {
        }

        public override ISamplingPipeline Clone()
        {
            throw new NotSupportedException();
        }

        protected override void ProcessLogits(SafeLLamaContextHandle ctx, Span&lt;float&gt; logits, ReadOnlySpan&lt;LLamaToken&gt; lastTokens)
        {
            if (guidance == null)
                return;

            // Get the logits generated by the guidance sequences
            var guidanceLogits = guidance.Sample();

            // Use those logits to guide this sequence
            NativeApi.llama_sample_apply_guidance(ctx, logits, guidanceLogits, weight);
        }

        protected override LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan&lt;LLamaToken&gt; lastTokens)
        {
            candidates.Temperature(ctx, 0.8f);
            candidates.TopK(ctx, 25);

            return candidates.SampleToken(ctx);
        }
    }
}
</code></pre>
<h2 id="inference-parameters">Inference parameters</h2>
<p>Different from context parameters, which is indicated in <a href="../UnderstandLLamaContext/">understand-llama-context</a>, executors accept parameters when you call its API to execute the inference. That means you could change the parameters every time you ask the model to generate the outputs.</p>
<p>Here is the parameters for LLamaSharp executors.</p>
<pre><code class="language-cs">/// &lt;summary&gt;
/// The paramters used for inference.
/// &lt;/summary&gt;
public record InferenceParams
    : IInferenceParams
{
    /// &lt;summary&gt;
    /// number of tokens to keep from initial prompt
    /// &lt;/summary&gt;
    public int TokensKeep { get; set; } = 0;

    /// &lt;summary&gt;
    /// how many new tokens to predict (n_predict), set to -1 to inifinitely generate response
    /// until it complete.
    /// &lt;/summary&gt;
    public int MaxTokens { get; set; } = -1;

    /// &lt;summary&gt;
    /// logit bias for specific tokens
    /// &lt;/summary&gt;
    public Dictionary&lt;LLamaToken, float&gt;? LogitBias { get; set; } = null;

    /// &lt;summary&gt;
    /// Sequences where the model will stop generating further tokens.
    /// &lt;/summary&gt;
    public IReadOnlyList&lt;string&gt; AntiPrompts { get; set; } = Array.Empty&lt;string&gt;();

    /// &lt;inheritdoc /&gt;
    public int TopK { get; set; } = 40;

    /// &lt;inheritdoc /&gt;
    public float TopP { get; set; } = 0.95f;

    /// &lt;inheritdoc /&gt;
    public float MinP { get; set; } = 0.05f;

    /// &lt;inheritdoc /&gt;
    public float TfsZ { get; set; } = 1.0f;

    /// &lt;inheritdoc /&gt;
    public float TypicalP { get; set; } = 1.0f;

    /// &lt;inheritdoc /&gt;
    public float Temperature { get; set; } = 0.8f;

    /// &lt;inheritdoc /&gt;
    public float RepeatPenalty { get; set; } = 1.1f;

    /// &lt;inheritdoc /&gt;
    public int RepeatLastTokensCount { get; set; } = 64;

    /// &lt;inheritdoc /&gt;
    public float FrequencyPenalty { get; set; } = .0f;

    /// &lt;inheritdoc /&gt;
    public float PresencePenalty { get; set; } = .0f;

    /// &lt;inheritdoc /&gt;
    public MirostatType Mirostat { get; set; } = MirostatType.Disable;

    /// &lt;inheritdoc /&gt;
    public float MirostatTau { get; set; } = 5.0f;

    /// &lt;inheritdoc /&gt;
    public float MirostatEta { get; set; } = 0.1f;

    /// &lt;inheritdoc /&gt;
    public bool PenalizeNL { get; set; } = true;

    /// &lt;inheritdoc /&gt;
    public SafeLLamaGrammarHandle? Grammar { get; set; }

    /// &lt;inheritdoc /&gt;
    public ISamplingPipeline? SamplingPipeline { get; set; }
}
</code></pre>
<h2 id="save-and-load-executor-state">Save and load executor state</h2>
<p>An executor also has its state, which can be saved and loaded. That means a lot when you want to support restore a previous session for the user in your application.</p>
<p>The following code shows how to use save and load executor state.</p>
<pre><code class="language-cs">InteractiveExecutor executor = new InteractiveExecutor(model);
// do some things...
executor.SaveState(&quot;executor.st&quot;);
var stateData = executor.GetStateData();

InteractiveExecutor executor2 = new InteractiveExecutor(model);
executor2.LoadState(stateData);
// do some things...

InteractiveExecutor executor3 = new InteractiveExecutor(model);
executor3.LoadState(&quot;executor.st&quot;);
// do some things...
</code></pre>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.bd41221c.min.js"></script>
      
    
  </body>
</html>