using LLama.Abstractions;
using System;
using System.Collections.Generic;
using System.Text;

namespace LLama.Control
{
    /// <summary>
    /// Control the text generation of LLama Executors.
    /// </summary>
    public interface IGenerationControl
    {
        /// <summary>
        /// Use the last output text to determine if the generation should stop.
        /// This method will be called after the overload with output id.
        /// The text will be returned even if this returns true but the generation will be stopped.
        /// </summary>
        /// <param name="context">The LLamaContext used in the current generation.</param>
        /// <param name="inferenceParams">The inference params used in the current generation.</param>
        /// <param name="lastOutputText">The last output text generated by the model.</param>
        /// <returns></returns>
        bool ShouldStopGeneration(LLamaContext context, IInferenceParams inferenceParams, string lastOutputText);

        /// <summary>
        /// Use the last output token to determine if the generation should stop.
        /// This method will be called before the overload with output text.
        /// The token will be returned even if this returns true but the generation will be stopped.
        /// </summary>
        /// <param name="context">The LLamaContext used in the current generation.</param>
        /// <param name="inferenceParams">The inference params used in the current generation.</param>
        /// <param name="lastOutputId">The last output token generated by the model.</param>
        /// <returns></returns>
        bool ShouldStopGeneration(LLamaContext context, IInferenceParams inferenceParams, int lastOutputId);
    }
}
